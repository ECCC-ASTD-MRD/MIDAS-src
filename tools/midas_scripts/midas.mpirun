#!/bin/bash

## Ce script est un wrapper autour de `r.run_in_parallel` pour rassembler
## le code qui doit être exécuté avant de lancer le MPI.

set -ex

__midas_mpirun_pgm__=$1
shift
__midas_mpirun_msg__=$1
shift
__midas_mpirun_ssm__=$1
shift
__midas_mpirun_OMP_STACKSIZE__=$1
shift
## Cette variable doit inclure l'appel a 'r.run_in_parallel' comme par exemple
##     ${TASK_BIN}/r.run_in_parallel -npex 10 -npey 10
__midas_mpirun_call_program__=$@

if [ -x ${SEQ_BIN}/nodelogger ]; then
    __midas_mpirun_nodelogger__=${SEQ_BIN}/nodelogger
else
    __midas_mpirun_nodelogger__=$(which nodelogger || true)
    if [ -z "${__midas_mpirun_nodelogger__}" ]; then
	function nodelogger {
	    echo $*
	}
	__midas_mpirun_nodelogger__=nodelogger
    fi
fi

${__midas_mpirun_nodelogger__} -n $SEQ_NODE -s infox -m  "Launching program ${__midas_mpirun_msg__}"
unset __midas_mpirun_msg__ __midas_mpirun_nodelogger__

export OMP_STACKSIZE=${__midas_mpirun_OMP_STACKSIZE__}
unset __midas_mpirun_OMP_STACKSIZE__

if [ "${EC_ARCH}" = ubuntu-18.04-skylake-64 ]; then
    set +x
    for __midas_mpirun_ssmdomain__ in ${__midas_mpirun_ssm__}; do
	echo "loading SSM domain '${__midas_mpirun_ssmdomain__}'"
	. ssmuse-sh -d ${__midas_mpirun_ssmdomain__}
    done
    unset __midas_mpirun_ssmdomain__
    set -x
elif [ "${EC_ARCH}" = rhel-8-icelake-64 ]; then
    echo "Setting variables to run with MPI with compiler 'inteloneapi-2022.1.2'"
    #. ssmuse-sh -x main/opt/intelcomp/inteloneapi-2022.1.2

    # instead of loading the whole OneAPI Intel compiler environment above,
    # we only load the essential things to be able to run
    #    see https://gitlab.science.gc.ca/hpc/hpcr_upgrade_2/issues/72#note_412503
    . /fs/ssm/main/opt/intelcomp/master/inteloneapi_2022.1.2_multi/oneapi/compiler/2022.0.2/env/vars.sh
    . /fs/ssm/main/opt/intelcomp/master/inteloneapi_2022.1.2_multi/oneapi/mpi/2021.5.1/env/vars.sh
    export I_MPI_F77=ifort
    export I_MPI_F90=ifort
    export I_MPI_FC=ifort
    export I_MPI_CC=icc
    export I_MPI_CXX=icpc

elif [ "${EC_ARCH}" = sles-15-skylake-64-xc50/PrgEnv-intel-6.0.5 ]; then
    ## This allows us to save 7% of computation time without changing the results!
    ## export TBB_MALLOC_USE_HUGE_PAGES=1
    module load craype-hugepages16M
    export FOR_DISABLE_KMP_MALLOC=0
else
    echo "midas.mpirun: The plateform 'EC_ARCH=${EC_ARCH}' is not supported (only 'ubuntu-18.04-skylake-64', 'rhel-8-icelake-64' and 'sles-15-skylake-64-xc50/PrgEnv-intel-6.0.5' are)"
    exit 1
fi

## find 'npex' and 'npey' in '${__midas_mpirun_call_program__}'
npex=1
npey=1
set -- ${__midas_mpirun_call_program__}
while [ $# -ne 0 ]; do
    case $1 in
        -npex)
            npex=$2
            shift
            ;;
        -npey)
            npey=$2
            shift
            ;;
    esac
    shift
done

SECONDS=0
## create indiviual trace for each rank
for rank in $(seq 0 $((npex*npey-1))); do
    date +%Y%m%d:%H:%M:%S.%N > touch.before.launch.${rank}
done
echo "The files 'touch.before.launch.*' have been created in ${SECONDS} seconds"

cat > midas.mpi_script.sh <<EOF
#!/bin/bash

set -ex

SECONDS=0

status=0
${__midas_mpirun_pgm__} \$@ || status=1

if [ "\${status}" -ne 0 ]; then
    echo "The MPI execution aborted!"
    exit 1
fi

$(which echo) MP_CHILD=\${MP_CHILD} \$($(which date) +%Y%m%d:%H:%M:%S.%N) before erasing touch.before.launch.\${MP_CHILD}
$(which rm)   ${PWD}/touch.before.launch.\${MP_CHILD}
$(which echo) MP_CHILD=\${MP_CHILD} \$($(which date) +%Y%m%d:%H:%M:%S.%N) after erasing touch.before.launch.\${MP_CHILD}

echo SECONDS=\${SECONDS}

EOF
chmod u+x midas.mpi_script.sh


status=0

SECONDS=0
${__midas_mpirun_call_program__} -processorder -tag -nocleanup -verbose -pgm ${PWD}/midas.mpi_script.sh || status=1
echo "The whole MPI execution took ${SECONDS} seconds"

unset __midas_mpirun_call_program__ __midas_mpirun_pgm__

SECONDS=0

if [ "${status}" -ne 0 ]; then
    echo "The whole MPI execution aborted!"
    exit 1
fi

## Check if all individual MPI tiles ran without errors
abortedRanks=$(/bin/ls touch.before.launch.* 2>/dev/null || true)
if [ -n "${abortedRanks}" ]; then
    echo "Some MPI ranks aborted!"
    echo ${abortedRanks}
    echo "The execution verification took ${SECONDS} seconds"
    exit 1
fi

echo "The execution verification took ${SECONDS} seconds"
